{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Lab\n",
    "![LeNet Architecture](resources/lenet.png)\n",
    "Source: Yan LeCun\n",
    "\n",
    "\n",
    "- the LeNet lab from the convolutional neural networks lesson is a great starting point for building a network to classify traffic signs\n",
    "- but before you adapt LeNet for the project, let's walk through the lab solution and review what happens on each line\n",
    "\n",
    "\n",
    "- image above shows original drawing of the LeNet architecture from Yan LeCun's 1998 journal article\n",
    "- the network takes a 32x32 images input\n",
    "- then, that image goes through a convolutional layer, C1, followed by a subsampling layer, S2\n",
    "  - since LeNet was originally designed, subsampling layers have mostly given way to what we now call pooling layers which is actually what we use in this lab\n",
    "- then there's another sequence of convolutional layer, C3, followed by a pooling layer, S4\n",
    "- finally, there are three fully connected layers including the output layer at the end\n",
    "- that's the architecture of LeNet\n",
    "\n",
    "\n",
    "- the rest of the notebook implements this architecture in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab info\n",
    "\n",
    "- reprocessing\n",
    "  - an MNIST image is initially $784$ features (1D)\n",
    "  - if the data is not normalized from $[0, 255]$ to $[0, 1]$, normalize it\n",
    "  - we reshape this to $(28, 28, 1)$ (3D), and pad the image with $0$s such that the height and width are $32$ (centers digit further)\n",
    "  - thus, the input shape going into the first convolutional layer is $32x32x1$\n",
    "\n",
    "\n",
    "- specs\n",
    "  - convolution layer 1\n",
    "    - the output shape should be $28x28x6$\n",
    "  - activation 1\n",
    "    - your choice of activation function\n",
    "  - pooling layer 1\n",
    "    - the output shape should be $14x14x6$\n",
    "  - convolution layer 2\n",
    "    - the output shape should be $10x10x16$\n",
    "  - activation 2\n",
    "    - your choice of activation function\n",
    "  - pooling layer 2\n",
    "    - the output shape should be $5x5x16$\n",
    "  - flatten layer\n",
    "    - flatten the output shape of the final pooling layer such that it's 1D instead of 3D\n",
    "    - the easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you\n",
    "  - fully connected layer 1\n",
    "    - this should have 120 outputs\n",
    "  - activation 3\n",
    "    - your choice of activation function\n",
    "  - fully connected layer 2\n",
    "    - this should have 84 outputs\n",
    "  - activation 4\n",
    "    - your choice of activation function\n",
    "  - fully connected layer 3\n",
    "    - this should have 10 outputs\n",
    "\n",
    "\n",
    "- you'll return the result of the final fully connected layer from the LeNet function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if implemented correctly you should see output similar to the following:\n",
    "\n",
    "```python\n",
    "EPOCH 1 ...\n",
    "Validation loss = 52.809\n",
    "Validation accuracy = 0.864\n",
    "\n",
    "EPOCH 2 ...\n",
    "Validation loss = 24.749\n",
    "Validation accuracy = 0.915\n",
    "\n",
    "EPOCH 3 ...\n",
    "Validation loss = 17.719\n",
    "Validation accuracy = 0.930\n",
    "\n",
    "EPOCH 4 ...\n",
    "Validation loss = 12.188\n",
    "Validation accuracy = 0.943\n",
    "\n",
    "EPOCH 5 ...\n",
    "Validation loss = 8.935\n",
    "Validation accuracy = 0.954\n",
    "\n",
    "EPOCH 6 ...\n",
    "Validation loss = 7.674\n",
    "Validation accuracy = 0.956\n",
    "\n",
    "EPOCH 7 ...\n",
    "Validation loss = 6.822\n",
    "Validation accuracy = 0.956\n",
    "\n",
    "EPOCH 8 ...\n",
    "Validation loss = 5.451\n",
    "Validation accuracy = 0.961\n",
    "\n",
    "EPOCH 9 ...\n",
    "Validation loss = 4.881\n",
    "Validation accuracy = 0.964\n",
    "\n",
    "EPOCH 10 ...\n",
    "Validation loss = 4.623\n",
    "Validation accuracy = 0.964\n",
    "\n",
    "Test loss = 4.726\n",
    "Test accuracy = 0.962\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-5e4d8a328c84>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/luka/miniconda3/envs/carnd-term1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/luka/miniconda3/envs/carnd-term1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/luka/miniconda3/envs/carnd-term1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/luka/miniconda3/envs/carnd-term1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/luka/miniconda3/envs/carnd-term1/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# load the MNIST data set which comes pre-installed with TensorFlow\\nfrom tensorflow.examples.tutorials.mnist import input_data\\n\\n# store the training validation and test sets\\nmnist = input_data.read_data_sets(\\\"MNIST_data/\\\", reshape=False)\\nX_train, y_train = mnist.train.images, mnist.train.labels\\nX_validation, y_validation = mnist.validation.images, mnist.validation.labels\\nX_test, y_test = mnist.test.images, mnist.test.labels\\n\\n# verify that the number of images in each set matches the number of labels in the same set\\nassert len(X_train) == len(y_train)\\nassert len(X_validation) == len(y_validation)\\nassert len(X_test) == len(y_test)\\n\\nprint()\\n# print out the shape of one image so that we know what the dimensions of the data are\\nprint(\\\"Image Shape: {}\\\".format(X_train[0].shape))\\nprint()\\n# print out the size of each set\\nprint(\\\"Training Set:   {} samples\\\".format(len(X_train)))\\nprint(\\\"Validation Set: {} samples\\\".format(len(X_validation)))\\nprint(\\\"Test Set:       {} samples\\\".format(len(X_test)))\";\n",
       "                var nbb_formatted_code = \"# load the MNIST data set which comes pre-installed with TensorFlow\\nfrom tensorflow.examples.tutorials.mnist import input_data\\n\\n# store the training validation and test sets\\nmnist = input_data.read_data_sets(\\\"MNIST_data/\\\", reshape=False)\\nX_train, y_train = mnist.train.images, mnist.train.labels\\nX_validation, y_validation = mnist.validation.images, mnist.validation.labels\\nX_test, y_test = mnist.test.images, mnist.test.labels\\n\\n# verify that the number of images in each set matches the number of labels in the same set\\nassert len(X_train) == len(y_train)\\nassert len(X_validation) == len(y_validation)\\nassert len(X_test) == len(y_test)\\n\\nprint()\\n# print out the shape of one image so that we know what the dimensions of the data are\\nprint(\\\"Image Shape: {}\\\".format(X_train[0].shape))\\nprint()\\n# print out the size of each set\\nprint(\\\"Training Set:   {} samples\\\".format(len(X_train)))\\nprint(\\\"Validation Set: {} samples\\\".format(len(X_validation)))\\nprint(\\\"Test Set:       {} samples\\\".format(len(X_test)))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the MNIST data set which comes pre-installed with TensorFlow\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# store the training validation and test sets\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "\n",
    "# verify that the number of images in each set matches the number of labels in the same set\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_validation) == len(y_validation)\n",
    "assert len(X_test) == len(y_test)\n",
    "\n",
    "print()\n",
    "# print out the shape of one image so that we know what the dimensions of the data are\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
    "print()\n",
    "# print out the size of each set\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the code, we see that the training set has 55,000 images. The validation set has 5,000 images and the test set has 10,000 images.\n",
    "\n",
    "The MNIST data that TensorFlow pre-loads comes as 28x28x1 images.\n",
    "\n",
    "However, the LeNet architecture only accepts 32x32xC images, where C is the number of color channels.\n",
    "\n",
    "In order to reformat the MNIST data into a shape that LeNet will accept, we pad the data with two rows of zeros on the top and bottom, and two columns of zeros on the left and right (28+2+2 = 32).\n",
    "\n",
    "We could do this by using image processing software to scale up each image.But here, we just pad the images with zeroes around the edges. This is much faster and it works well. When we've done, the image shape is 32 by 32 by 1 which is exactly what LeNet takes as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\n\\n# Pad images with 0s\\n# transform the 28 by 28 MNIST images into 32 by 32 images that LeNet can process\\nX_train = np.pad(X_train, ((0, 0), (2, 2), (2, 2), (0, 0)), \\\"constant\\\")\\nX_validation = np.pad(X_validation, ((0, 0), (2, 2), (2, 2), (0, 0)), \\\"constant\\\")\\nX_test = np.pad(X_test, ((0, 0), (2, 2), (2, 2), (0, 0)), \\\"constant\\\")\\n\\nprint(\\\"Updated Image Shape: {}\\\".format(X_train[0].shape))\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\n\\n# Pad images with 0s\\n# transform the 28 by 28 MNIST images into 32 by 32 images that LeNet can process\\nX_train = np.pad(X_train, ((0, 0), (2, 2), (2, 2), (0, 0)), \\\"constant\\\")\\nX_validation = np.pad(X_validation, ((0, 0), (2, 2), (2, 2), (0, 0)), \\\"constant\\\")\\nX_test = np.pad(X_test, ((0, 0), (2, 2), (2, 2), (0, 0)), \\\"constant\\\")\\n\\nprint(\\\"Updated Image Shape: {}\\\".format(X_train[0].shape))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pad images with 0s\n",
    "# transform the 28 by 28 MNIST images into 32 by 32 images that LeNet can process\n",
    "X_train = np.pad(X_train, ((0, 0), (2, 2), (2, 2), (0, 0)), \"constant\")\n",
    "X_validation = np.pad(X_validation, ((0, 0), (2, 2), (2, 2), (0, 0)), \"constant\")\n",
    "X_test = np.pad(X_test, ((0, 0), (2, 2), (2, 2), (0, 0)), \"constant\")\n",
    "\n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "\n",
    "View a sample from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import random\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n\\n# select a random image from the training set and uaw matplotlib to visualize it\\nindex = random.randint(0, len(X_train))\\nimage = X_train[index].squeeze()\\n\\nplt.figure(figsize=(1, 1))\\nplt.imshow(image, cmap=\\\"gray\\\")\\n\\n# print out the label for that image\\nprint(y_train[index])\";\n",
       "                var nbb_formatted_code = \"import random\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n\\n# select a random image from the training set and uaw matplotlib to visualize it\\nindex = random.randint(0, len(X_train))\\nimage = X_train[index].squeeze()\\n\\nplt.figure(figsize=(1, 1))\\nplt.imshow(image, cmap=\\\"gray\\\")\\n\\n# print out the label for that image\\nprint(y_train[index])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# select a random image from the training set and uaw matplotlib to visualize it\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1, 1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "# print out the label for that image\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data.\n",
    "\n",
    "It's important to shuffle the training data, otherwise the ordering of the data might have a huge effect on how well the network trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from sklearn.utils import shuffle\\n\\nX_train, y_train = shuffle(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"from sklearn.utils import shuffle\\n\\nX_train, y_train = shuffle(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "We will use this `EPOCHS` variable, to tell TensorFlow how many times to run our training data through the network. In general, the more EPOCHS, the better our model will train, but also the longer training will take.\n",
    "\n",
    "Later we'll also use the `BATCH_SIZE` variable to tell TensorFlow how many training images to run through the network at a time. The larger the batch size, the faster our model will train, but our processor may have a memory limit on how large a batch it can run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"import tensorflow as tf\\n\\nEPOCHS = 10\\nBATCH_SIZE = 128\";\n",
       "                var nbb_formatted_code = \"import tensorflow as tf\\n\\nEPOCHS = 10\\nBATCH_SIZE = 128\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6. The formula for convolutions tells us that the output height equals the input height minus the filter height plus one all divided by the vertical stride.\n",
    "In this case, that means 32, minus 5, plus 2, all divided by 1, which equals 28. The formula works the same way for the output width, which also equals 28. So our convolutional layer output is 28 by 28 by 6. That's our first convolutional layer.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"from tensorflow.contrib.layers import flatten\\n\\n\\ndef LeNet(x):\\n    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\\n    mu = 0\\n    sigma = 0.1\\n\\n    ### LAYER1 ###\\n    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\\n    # this layer has 5x5 filter with an input depth of 1, and an output depth of 6\\n    conv1_W = tf.Variable(\\n        tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma)\\n    )\\n    # initialize the bias\\n    conv1_b = tf.Variable(tf.zeros(6))\\n    # use the conv2D function to convolve the filter over the images, and we add the bias at the end\\n    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding=\\\"VALID\\\") + conv1_b\\n\\n    # TODO: Activation.\\n    # activate the output of the convolutional layer, in this case with a ReLU activation function\\n    conv1 = tf.nn.relu(conv1)\\n\\n    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\\n    # pool the output using the 2 by 2 kernel with a 2 by 2 stride, which gives us a pooling output of 14 by 14 by 6\\n    # the network then runs through another set of convolutional activation and pooling layers, giving an output of 5 by 5 by 16\\n    conv1 = tf.nn.max_pool(\\n        conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\\\"VALID\\\"\\n    )\\n\\n    ### LAYER2 ###\\n    # TODO: Layer 2: Convolutional. Output = 10x10x16.\\n    conv2_W = tf.Variable(\\n        tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma)\\n    )\\n    conv2_b = tf.Variable(tf.zeros(16))\\n    conv2 = (\\n        tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding=\\\"VALID\\\") + conv2_b\\n    )\\n\\n    # TODO: Activation.\\n    conv2 = tf.nn.relu(conv2)\\n\\n    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\\n    conv2 = tf.nn.max_pool(\\n        conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\\\"VALID\\\"\\n    )\\n\\n    # TODO: Flatten. Input = 5x5x16. Output = 400.\\n    # flatten this output into a vector; the length of the vector is 5 times 5 times 16, which equals 400\\n    fc0 = flatten(conv2)\\n\\n    ### LAYER3 ###\\n    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\\n    # pass this vector into a fully connected layer, with a width of 120\\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean=mu, stddev=sigma))\\n    fc1_b = tf.Variable(tf.zeros(120))\\n    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\\n\\n    # TODO: Activation.\\n    # apply a ReLU activation to the output of this fully connected layer\\n    fc1 = tf.nn.relu(fc1)\\n\\n    ### LAYER4 ###\\n    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\\n    # repeat the pattern again this time with a layer width of 84\\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 84), mean=mu, stddev=sigma))\\n    fc2_b = tf.Variable(tf.zeros(84))\\n    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\\n\\n    # TODO: Activation.\\n    fc2 = tf.nn.relu(fc2)\\n\\n    ### LAYER5 ###\\n    # TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\\n    # attach a fully connected output layer with a width equal to the number of classes in our label set\\n    # in this case,we have 10 classes; one for each digit, so the with the the output layer is 10\\n    # these outputs are also known as our logits, which is what we return from the LeNet function\\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 10), mean=mu, stddev=sigma))\\n    fc3_b = tf.Variable(tf.zeros(10))\\n    logits = tf.matmul(fc2, fc3_W) + fc3_b\\n\\n    return logits\";\n",
       "                var nbb_formatted_code = \"from tensorflow.contrib.layers import flatten\\n\\n\\ndef LeNet(x):\\n    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\\n    mu = 0\\n    sigma = 0.1\\n\\n    ### LAYER1 ###\\n    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\\n    # this layer has 5x5 filter with an input depth of 1, and an output depth of 6\\n    conv1_W = tf.Variable(\\n        tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma)\\n    )\\n    # initialize the bias\\n    conv1_b = tf.Variable(tf.zeros(6))\\n    # use the conv2D function to convolve the filter over the images, and we add the bias at the end\\n    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding=\\\"VALID\\\") + conv1_b\\n\\n    # TODO: Activation.\\n    # activate the output of the convolutional layer, in this case with a ReLU activation function\\n    conv1 = tf.nn.relu(conv1)\\n\\n    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\\n    # pool the output using the 2 by 2 kernel with a 2 by 2 stride, which gives us a pooling output of 14 by 14 by 6\\n    # the network then runs through another set of convolutional activation and pooling layers, giving an output of 5 by 5 by 16\\n    conv1 = tf.nn.max_pool(\\n        conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\\\"VALID\\\"\\n    )\\n\\n    ### LAYER2 ###\\n    # TODO: Layer 2: Convolutional. Output = 10x10x16.\\n    conv2_W = tf.Variable(\\n        tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma)\\n    )\\n    conv2_b = tf.Variable(tf.zeros(16))\\n    conv2 = (\\n        tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding=\\\"VALID\\\") + conv2_b\\n    )\\n\\n    # TODO: Activation.\\n    conv2 = tf.nn.relu(conv2)\\n\\n    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\\n    conv2 = tf.nn.max_pool(\\n        conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\\\"VALID\\\"\\n    )\\n\\n    # TODO: Flatten. Input = 5x5x16. Output = 400.\\n    # flatten this output into a vector; the length of the vector is 5 times 5 times 16, which equals 400\\n    fc0 = flatten(conv2)\\n\\n    ### LAYER3 ###\\n    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\\n    # pass this vector into a fully connected layer, with a width of 120\\n    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean=mu, stddev=sigma))\\n    fc1_b = tf.Variable(tf.zeros(120))\\n    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\\n\\n    # TODO: Activation.\\n    # apply a ReLU activation to the output of this fully connected layer\\n    fc1 = tf.nn.relu(fc1)\\n\\n    ### LAYER4 ###\\n    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\\n    # repeat the pattern again this time with a layer width of 84\\n    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 84), mean=mu, stddev=sigma))\\n    fc2_b = tf.Variable(tf.zeros(84))\\n    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\\n\\n    # TODO: Activation.\\n    fc2 = tf.nn.relu(fc2)\\n\\n    ### LAYER5 ###\\n    # TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\\n    # attach a fully connected output layer with a width equal to the number of classes in our label set\\n    # in this case,we have 10 classes; one for each digit, so the with the the output layer is 10\\n    # these outputs are also known as our logits, which is what we return from the LeNet function\\n    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 10), mean=mu, stddev=sigma))\\n    fc3_b = tf.Variable(tf.zeros(10))\\n    logits = tf.matmul(fc2, fc3_W) + fc3_b\\n\\n    return logits\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "\n",
    "def LeNet(x):\n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "\n",
    "    ### LAYER1 ###\n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    # this layer has 5x5 filter with an input depth of 1, and an output depth of 6\n",
    "    conv1_W = tf.Variable(\n",
    "        tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma)\n",
    "    )\n",
    "    # initialize the bias\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    # use the conv2D function to convolve the filter over the images, and we add the bias at the end\n",
    "    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding=\"VALID\") + conv1_b\n",
    "\n",
    "    # TODO: Activation.\n",
    "    # activate the output of the convolutional layer, in this case with a ReLU activation function\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    # pool the output using the 2 by 2 kernel with a 2 by 2 stride, which gives us a pooling output of 14 by 14 by 6\n",
    "    # the network then runs through another set of convolutional activation and pooling layers, giving an output of 5 by 5 by 16\n",
    "    conv1 = tf.nn.max_pool(\n",
    "        conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\"\n",
    "    )\n",
    "\n",
    "    ### LAYER2 ###\n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(\n",
    "        tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma)\n",
    "    )\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2 = (\n",
    "        tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding=\"VALID\") + conv2_b\n",
    "    )\n",
    "\n",
    "    # TODO: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(\n",
    "        conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\"\n",
    "    )\n",
    "\n",
    "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    "    # flatten this output into a vector; the length of the vector is 5 times 5 times 16, which equals 400\n",
    "    fc0 = flatten(conv2)\n",
    "\n",
    "    ### LAYER3 ###\n",
    "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    # pass this vector into a fully connected layer, with a width of 120\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean=mu, stddev=sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "\n",
    "    # TODO: Activation.\n",
    "    # apply a ReLU activation to the output of this fully connected layer\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    ### LAYER4 ###\n",
    "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    # repeat the pattern again this time with a layer width of 84\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 84), mean=mu, stddev=sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "\n",
    "    # TODO: Activation.\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "    ### LAYER5 ###\n",
    "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    # attach a fully connected output layer with a width equal to the number of classes in our label set\n",
    "    # in this case,we have 10 classes; one for each digit, so the with the the output layer is 10\n",
    "    # these outputs are also known as our logits, which is what we return from the LeNet function\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 10), mean=mu, stddev=sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# x is a placeholder for a batch of input images (batches)\\n# initialize the batch size to None, which allows the placeholder to later accept a batch of any size\\n# and we set the image dimensions to 32 by 32 by 1\\nx = tf.placeholder(tf.float32, (None, 32, 32, 1))\\n\\n# y is a placeholder for a batch of output labels\\n# in this case, our labels come through with sparse variables, which just means that they're integers\\n# they aren't one-hot encoded yet\\ny = tf.placeholder(tf.int32, (None))\\n\\n# one-hot encode the labels\\none_hot_y = tf.one_hot(y, 10)\";\n",
       "                var nbb_formatted_code = \"# x is a placeholder for a batch of input images (batches)\\n# initialize the batch size to None, which allows the placeholder to later accept a batch of any size\\n# and we set the image dimensions to 32 by 32 by 1\\nx = tf.placeholder(tf.float32, (None, 32, 32, 1))\\n\\n# y is a placeholder for a batch of output labels\\n# in this case, our labels come through with sparse variables, which just means that they're integers\\n# they aren't one-hot encoded yet\\ny = tf.placeholder(tf.int32, (None))\\n\\n# one-hot encode the labels\\none_hot_y = tf.one_hot(y, 10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x is a placeholder for a batch of input images (batches)\n",
    "# initialize the batch size to None, which allows the placeholder to later accept a batch of any size\n",
    "# and we set the image dimensions to 32 by 32 by 1\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "\n",
    "# y is a placeholder for a batch of output labels\n",
    "# in this case, our labels come through with sparse variables, which just means that they're integers\n",
    "# they aren't one-hot encoded yet\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "# one-hot encode the labels\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/luka/miniconda3/envs/carnd-term1/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/luka/miniconda3/envs/carnd-term1/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-9-d1033c814782>:9: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# the learning rate tells TensorFlow how quickly to update the network's weights\\nrate = 0.001\\n\\n# pass the input data to the LeNet function to calculate our logits\\nlogits = LeNet(x)\\n\\n# compare those logits to the ground truth labels and calculate the cross entropy\\n# cross entropy is just a measure of how different the logits are from the ground truth training labels\\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\\n\\n# average the cross entropy from all of the training images\\nloss_operation = tf.reduce_mean(cross_entropy)\\n\\n# AdamOptimizer uses the Adam algorithm to minimize the loss function similarly to what stochastic gradient descent does\\n# so it's a good default choice for an optimizer\\noptimizer = tf.train.AdamOptimizer(learning_rate=rate)\\n\\n# run the minimize function on the optimizer which uses backpropagation to update the network and minimize our training loss\\ntraining_operation = optimizer.minimize(loss_operation)\";\n",
       "                var nbb_formatted_code = \"# the learning rate tells TensorFlow how quickly to update the network's weights\\nrate = 0.001\\n\\n# pass the input data to the LeNet function to calculate our logits\\nlogits = LeNet(x)\\n\\n# compare those logits to the ground truth labels and calculate the cross entropy\\n# cross entropy is just a measure of how different the logits are from the ground truth training labels\\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\\n\\n# average the cross entropy from all of the training images\\nloss_operation = tf.reduce_mean(cross_entropy)\\n\\n# AdamOptimizer uses the Adam algorithm to minimize the loss function similarly to what stochastic gradient descent does\\n# so it's a good default choice for an optimizer\\noptimizer = tf.train.AdamOptimizer(learning_rate=rate)\\n\\n# run the minimize function on the optimizer which uses backpropagation to update the network and minimize our training loss\\ntraining_operation = optimizer.minimize(loss_operation)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the learning rate tells TensorFlow how quickly to update the network's weights\n",
    "rate = 0.001\n",
    "\n",
    "# pass the input data to the LeNet function to calculate our logits\n",
    "logits = LeNet(x)\n",
    "\n",
    "# compare those logits to the ground truth labels and calculate the cross entropy\n",
    "# cross entropy is just a measure of how different the logits are from the ground truth training labels\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "\n",
    "# average the cross entropy from all of the training images\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# AdamOptimizer uses the Adam algorithm to minimize the loss function similarly to what stochastic gradient descent does\n",
    "# so it's a good default choice for an optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=rate)\n",
    "\n",
    "# run the minimize function on the optimizer which uses backpropagation to update the network and minimize our training loss\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# measure whether a given prediction is correct by comparing the logit prediction to the one-hot encoded ground truth label\\ncorrect_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\\n\\n# calculate the model's overall accuracy by averaging the individual prediction accuracies\\naccuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\\n\\n# these two lines above are the entire evaluation pipeline\\n\\nsaver = tf.train.Saver()\\n\\n\\n# this function takes a dataset as input, sets some initial variables, and then batches the dataset and runs it through the evaluation pipeline\\n# the evaluate function averages the accuracy of each batch to calculate the total accuracy of the model\\ndef evaluate(X_data, y_data):\\n    num_examples = len(X_data)\\n    total_accuracy = 0\\n    sess = tf.get_default_session()\\n    for offset in range(0, num_examples, BATCH_SIZE):\\n        batch_x, batch_y = (\\n            X_data[offset : offset + BATCH_SIZE],\\n            y_data[offset : offset + BATCH_SIZE],\\n        )\\n        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\\n        total_accuracy += accuracy * len(batch_x)\\n    return total_accuracy / num_examples\";\n",
       "                var nbb_formatted_code = \"# measure whether a given prediction is correct by comparing the logit prediction to the one-hot encoded ground truth label\\ncorrect_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\\n\\n# calculate the model's overall accuracy by averaging the individual prediction accuracies\\naccuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\\n\\n# these two lines above are the entire evaluation pipeline\\n\\nsaver = tf.train.Saver()\\n\\n\\n# this function takes a dataset as input, sets some initial variables, and then batches the dataset and runs it through the evaluation pipeline\\n# the evaluate function averages the accuracy of each batch to calculate the total accuracy of the model\\ndef evaluate(X_data, y_data):\\n    num_examples = len(X_data)\\n    total_accuracy = 0\\n    sess = tf.get_default_session()\\n    for offset in range(0, num_examples, BATCH_SIZE):\\n        batch_x, batch_y = (\\n            X_data[offset : offset + BATCH_SIZE],\\n            y_data[offset : offset + BATCH_SIZE],\\n        )\\n        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\\n        total_accuracy += accuracy * len(batch_x)\\n    return total_accuracy / num_examples\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# measure whether a given prediction is correct by comparing the logit prediction to the one-hot encoded ground truth label\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "\n",
    "# calculate the model's overall accuracy by averaging the individual prediction accuracies\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# these two lines above are the entire evaluation pipeline\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "# this function takes a dataset as input, sets some initial variables, and then batches the dataset and runs it through the evaluation pipeline\n",
    "# the evaluate function averages the accuracy of each batch to calculate the total accuracy of the model\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = (\n",
    "            X_data[offset : offset + BATCH_SIZE],\n",
    "            y_data[offset : offset + BATCH_SIZE],\n",
    "        )\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += accuracy * len(batch_x)\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.967\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.987\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.987\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# create the TensorFlow session and initialize the variables\\nwith tf.Session() as sess:\\n    sess.run(tf.global_variables_initializer())\\n    num_examples = len(X_train)\\n\\n    print(\\\"Training...\\\")\\n    print()\\n    # train over whatever number of epochs has been set in the EPOCHS hyperparameter\\n    for i in range(EPOCHS):\\n        # at the beginning of each epoch, we shuffle our training data to ensure that our training isn't biased by the order of the images\\n        X_train, y_train = shuffle(X_train, y_train)\\n\\n        # break our training data into batches and train the model on each batch\\n        for offset in range(0, num_examples, BATCH_SIZE):\\n            end = offset + BATCH_SIZE\\n            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\\n            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\\n\\n        # at the end of each epoch, we evaluate the model on our validation data\\n        validation_accuracy = evaluate(X_validation, y_validation)\\n        print(\\\"EPOCH {} ...\\\".format(i + 1))\\n        print(\\\"Validation Accuracy = {:.3f}\\\".format(validation_accuracy))\\n        print()\\n\\n    saver.save(sess, \\\"./lenet\\\")\\n    print(\\\"Model saved\\\")\";\n",
       "                var nbb_formatted_code = \"# create the TensorFlow session and initialize the variables\\nwith tf.Session() as sess:\\n    sess.run(tf.global_variables_initializer())\\n    num_examples = len(X_train)\\n\\n    print(\\\"Training...\\\")\\n    print()\\n    # train over whatever number of epochs has been set in the EPOCHS hyperparameter\\n    for i in range(EPOCHS):\\n        # at the beginning of each epoch, we shuffle our training data to ensure that our training isn't biased by the order of the images\\n        X_train, y_train = shuffle(X_train, y_train)\\n\\n        # break our training data into batches and train the model on each batch\\n        for offset in range(0, num_examples, BATCH_SIZE):\\n            end = offset + BATCH_SIZE\\n            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\\n            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\\n\\n        # at the end of each epoch, we evaluate the model on our validation data\\n        validation_accuracy = evaluate(X_validation, y_validation)\\n        print(\\\"EPOCH {} ...\\\".format(i + 1))\\n        print(\\\"Validation Accuracy = {:.3f}\\\".format(validation_accuracy))\\n        print()\\n\\n    saver.save(sess, \\\"./lenet\\\")\\n    print(\\\"Model saved\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the TensorFlow session and initialize the variables\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    # train over whatever number of epochs has been set in the EPOCHS hyperparameter\n",
    "    for i in range(EPOCHS):\n",
    "        # at the beginning of each epoch, we shuffle our training data to ensure that our training isn't biased by the order of the images\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "        # break our training data into batches and train the model on each batch\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # at the end of each epoch, we evaluate the model on our validation data\n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i + 1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "\n",
    "    saver.save(sess, \"./lenet\")\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Remember, we should only run the model on the test dataset one time once we are completely done with training.\n",
    "Otherwise, we would be using the test dataset to choose the best model and then the test dataset wouldn't provide\n",
    "a good estimate of how well the model would do in the real world.\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.989\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"with tf.Session() as sess:\\n    saver.restore(sess, tf.train.latest_checkpoint(\\\".\\\"))\\n\\n    test_accuracy = evaluate(X_test, y_test)\\n    print(\\\"Test Accuracy = {:.3f}\\\".format(test_accuracy))\";\n",
       "                var nbb_formatted_code = \"with tf.Session() as sess:\\n    saver.restore(sess, tf.train.latest_checkpoint(\\\".\\\"))\\n\\n    test_accuracy = evaluate(X_test, y_test)\\n    print(\\\"Test Accuracy = {:.3f}\\\".format(test_accuracy))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\".\"))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
