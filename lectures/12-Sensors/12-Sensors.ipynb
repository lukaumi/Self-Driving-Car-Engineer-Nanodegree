{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we played a lot with images and camera images\n",
    "- as you might imagine, eyes for the machine are as important as our own eyes when we see the world\n",
    "- but we don't just have eyes, we have noses, we have ears, we have skin, we have built-in sensors that can measure the deflection of our muscles or we can understand the gravity points through our ears\n",
    "  - these sensors give us, people, the ability to have this kind of amazing image of the world, it goes way beyond computer vision\n",
    "- the same is true for cars\n",
    "  - there's sensors called radar, lidar or laser, and many other sensors\n",
    "  - a self-driving car expert takes input from all these data sources and turns then into coherent picture\n",
    "- why say more than one where it's completely obvious like your eyes can't smell and your nose can't hear and these different types of information are still important to live human life\n",
    "  - the same is true for car\n",
    "  - so, lidar is able to see distances which eyes have a hard time with, and radar can see sometimes through fog where visible lights can't go through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sensor Fusion has a car or any sensing robot for that matter, understand and track its environment\n",
    "  - the environment could consist of other cars, or barriers on the shoulder of the road, or motorcycles, or pedestrians walking across the road\n",
    "\n",
    "\n",
    "- by the end of this module, you'll implement your own sensor fusion algorithm to track a pedestrian relative to a car\n",
    "  - to do this you'll need to fuse lidar and radar data\n",
    "  - you'll be working with a technique called a Kalman filter; you'll start with a basic Kalman filter and then extend it to more complex data\n",
    "\n",
    "\n",
    "- sensor fusion needs to happen quickly, which means we need to use a high performance language\n",
    "- C++ is a critical language for performing real-time operations\n",
    "- we use it at Mercedes and you use it to build your project in this module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radar Strengths and Weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- two stereo cameras together, work just like our eyes to form a stereo image that allows us to gather both image data, as well as distance information\n",
    "- often, traffic signals can be located on the other side of an intersection, so we use a camera for the recognition of traffic signals with a special lens to give the camera sufficient range to detect the signal from far away\n",
    "\n",
    "\n",
    "- RADAR stands for **RAdio Detection And Ranging**\n",
    "- a radar sits behind the bumper\n",
    "- radars have in automobiles for years; you can find them in systems like adaptive cruise control, blind spot warning, collision warning and collision avoidance\n",
    "- even though radar is a mature technology, it still gets improved all the time to make it even more powerful\n",
    "- while other sensors measure velocity by calculating the difference between two readings, radar uses something called the *Doppler effect* to measure speed directly\n",
    "  - the Doppler effect measures the change in frequency of the radar waves based on whether the object is moving away from you or toward you\n",
    "    - this is kind of like how a fire engine siren will sound differently depending on whether the fire engine is moving away from you or toward you\n",
    "  - the Doppler effect is important for sensor fusion because it gives us the velocity as an independent measure parameter, and it makes the fusion algorithms converge much faster\n",
    "\n",
    "\n",
    "- radar can also be used for localization by generating radar maps of the environment\n",
    "- because radar waves bounce off hard surfaces, they can provide measurements to objects without direct line of flight\n",
    "- radar can see underneath other vehicles, and spot buildings and objects that would be obscured otherwise\n",
    "\n",
    "\n",
    "- of all the sensors on the car, radar is the least affected by rain or fog and can have a wide field of view, about 150 degrees, or a long range, 200 plus meters\n",
    "- compared to lidars and cameras, radars have a low resolution\n",
    "  - especially in the vertical direction, the resolution is very limited\n",
    "  - the lower resolution also means that reflections from static objects can cause problems\n",
    "    - for example, manhole covers or a soda can lying on the street can have high radar reflectivity even though they are relatively small\n",
    "    - this is called radar clutter, and it's why current automotive radars usually disregard static objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidar Strengths and Weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LIDAR stands for **Light Detection and Ranging** \n",
    "- unlike RADAR, which uses radio waves, LIDAR uses an infrared laser beam to determine the distance between the sensor and a nearby object\n",
    "- most current LIDARs use light in the 900 nanometer wavelength range, although some LIDARs use longer wavelengths, which perform better in rain and fog\n",
    "\n",
    "<img src=\"resources/lidar_wavelengths.png\" style=\"width: 70%;\">\n",
    "\n",
    "- in current LIDARs, a rotating swivel scans the laser beam across the field of view\n",
    "- the lasers are pulsed, and the pulses are reflected by objects\n",
    "  - these reflections return a point cloud that represents these objects\n",
    "\n",
    "<img src=\"resources/lidar_pulse.png\" style=\"width: 70%;\">\n",
    "\n",
    "<img src=\"resources/lidar_pointcloud.png\" style=\"width: 70%;\">\n",
    "\n",
    "- LIDAR has a much higher spatial resolution than RADAR because of the more focused laser beam, the larger number of scan layers in the vertical direction, and the high density of LIDAR points per layer\n",
    "- the current generation of LIDARs cannot measure the velocity of objects directly and have to rely on the differing position between two or more scans\n",
    "- LIDARs are also more affected by weather conditions and by dirt on the sensor, which requires keeping them clean\n",
    "- they are also much bulkier than other sensors and therefore, more difficult to integrate unless one just wants to mount a big scanner on the roof of the vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there are other possibilities to scan the laser beams\n",
    "  - instead of rotating the lasers or having a rotating mirror, we can scan the lidar with a vibrating micromirror\n",
    "  - those lidars are in development but none are commercially available now (as of March 2017)\n",
    "\n",
    "\n",
    "- instead of mechanically moving the laser beam, a similar principle to phased array radar can be employed\n",
    "- dividing a single laser beam into multiple waveguides, the phase relationship between the waveguides can be altered and thereby the direction of the laser beam shifted\n",
    "  - acompany named [Quanergy](http://quanergy.com/) is working on systems like that\n",
    "  - the advantage is that the form factor can be much smaller and that there are no moving parts\n",
    "\n",
    "\n",
    "- another possibility is to use the laser as a gigantic flash like with a camera and then measuring the arrival times for all the objects with one big imaging photodiode array\n",
    "- this is in effect a 3D camera\n",
    "- the components are currently very expensive and currently this is used more in space and in terrain mapping applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera, Radar and Lidar comparison\n",
    "\n",
    "<img src=\"resources/camera_radar_lidar_comparison.png\" style=\"width: 70%;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
