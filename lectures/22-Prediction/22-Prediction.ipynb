{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to understand what the prediction team does, imagine at T-shaped intersection\n",
    "- you are a self-driving car that has just pulled up to the stop sign\n",
    "- you want to turn left but your sensors notice another vehicle coming from the left\n",
    "- at this point, you as a human probably know the other vehicle will do one of two things - either it will go straight or it will go right\n",
    "- let's say that at this point, the other vehicle starts slowing down and moving right in the lane\n",
    "- you probably know that they are turning right which means it is safe for you to go left\n",
    "- by making a successful prediction, you were able to make a decision that got you to your destination safely and efficiently\n",
    "\n",
    "\n",
    "- what makes prediction interesting but also challenging is that it is inherently multi-modal\n",
    "- a good way of thinking about what that means is to think of how you would answer the question, \"Where is the other car likely to be in five seconds?\"\n",
    "- if we try to come up with the probability distribution, we would see that it has multiple peaks or modes\n",
    "\n",
    "<img src=\"resources/t_intersection_probability_distribution.png\"/>\n",
    "\n",
    "- if the car is going straight, then the car is likely to be somewhere here (green) but if the car turns right, then it's more likely to be here (blue)\n",
    "- in general, the way we think about handling multi-modal uncertainty is by maintaining some beliefs about how probable each potential mode is\n",
    "- initially, if we just see this green car coming from far away, those beliefs could be initialized using some prior knowledge about this intersection\n",
    "- in this case, let's say that cars generally go straight at this intersection, but as we continue watching the car, we may notice that it is slowing down\n",
    "- since this behavior is more consistent with turning right, the probability of turning right increases\n",
    "- and then, at the next timestep, we might notice that the car has already started turning right which again increases the probability of turning right\n",
    "- and as we keep observing, we continue updating our belief based on new evidence until eventually we can predict with high certainty that the vehicle is turning right at this intersection\n",
    "\n",
    "\n",
    "- the responsibility of the prediction module is to do the following:\n",
    "  - we take as input a map of the world and data from sensor fusion and generate as output some predictions of the future state of all the vehicles and other moving objects in the vicinity of our vehicle\n",
    "- typically, these predictions are represented by a set of possible trajectories like that two dotted arrows emanating from the green car in this scenario and an associated probability for each trajectory\n",
    "\n",
    "<img src=\"resources/t_intersection_trajectories_dotted.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- before we get into the details, let me explain what we are going to discuss in this lesson\n",
    "- first, we'll go through a brief overview where you will learn a bit more about the inputs and outputs to prediction\n",
    "- next, we will talk about how prediction is actually done\n",
    "  - we will discuss the two main classes of prediction techniques: model-based approaches and data-driven approaches\n",
    "    - model-based approaches use mathematical models of motion to predict trajectories\n",
    "    - data-driven approaches rely on machine learning and examples to learn from\n",
    "- then, I will briefly walk you through how to apply a strictly data-driven approach for prediction called trajectory clustering\n",
    "- then, we will dig into model-based approaches\n",
    "  - I'll introduce process models as a mathematical technique for modeling various maneuvers like lane changes, vehicle following, etc.\n",
    "  - I'll introduce multi-modal estimators as an effective technique for handling the uncertainty associated with prediction, namely, the uncertainty about which maneuver an object will do in a particular situation\n",
    "- finally, we will dive deep into hybrid approaches which use data and process models to predict motion through a cycle of intense classification where we try to figure out what a driver wants to do and trajectory generation\n",
    "  - there we try to figure out how they are likely to do it\n",
    "  - we will end by implementing an algorithm called Naive Bayes to predict the motion of a car at a T-shaped intersection like the one you just saw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/prediction_io_recap_directions.jpg\"/>\n",
    "\n",
    "- a prediction module uses a map and data from sensor fusion to generate predictions for what all other **dynamic** objects in view are likely to do\n",
    "- to make this clearer, let's look at an example (in json format) of what the input to and output from prediction might look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Input - Sensor Fusion\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"timestamp\" : 34512.21,\n",
    "    \"vehicles\" : [\n",
    "        {\n",
    "            \"id\"  : 0,\n",
    "            \"x\"   : -10.0,\n",
    "            \"y\"   : 8.1,\n",
    "            \"v_x\" : 8.0,\n",
    "            \"v_y\" : 0.0,\n",
    "            \"sigma_x\" : 0.031,\n",
    "            \"sigma_y\" : 0.040,\n",
    "            \"sigma_v_x\" : 0.12,\n",
    "            \"sigma_v_y\" : 0.03,\n",
    "        },\n",
    "        {\n",
    "            \"id\"  : 1,\n",
    "            \"x\"   : 10.0,\n",
    "            \"y\"   : 12.1,\n",
    "            \"v_x\" : -8.0,\n",
    "            \"v_y\" : 0.0,\n",
    "            \"sigma_x\" : 0.031,\n",
    "            \"sigma_y\" : 0.040,\n",
    "            \"sigma_v_x\" : 0.12,\n",
    "            \"sigma_v_y\" : 0.03,\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Output - Sensor Fusion\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"timestamp\" : 34512.21,\n",
    "    \"vehicles\" : [\n",
    "        {\n",
    "            \"id\" : 0,\n",
    "            \"length\": 3.4,\n",
    "            \"width\" : 1.5,\n",
    "            \"predictions\" : [\n",
    "                {\n",
    "                    \"probability\" : 0.781,\n",
    "                    \"trajectory\"  : [\n",
    "                        {\n",
    "                            \"x\": -10.0,\n",
    "                            \"y\": 8.1,\n",
    "                            \"yaw\": 0.0,\n",
    "                            \"timestamp\": 34512.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -6.0,\n",
    "                            \"y\": 8.1,\n",
    "                            \"yaw\": 0.0,\n",
    "                            \"timestamp\": 34513.21\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -2.0,\n",
    "                            \"y\": 8.1,\n",
    "                            \"yaw\": 0.0,\n",
    "                            \"timestamp\": 34513.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": 2.0,\n",
    "                            \"y\": 8.1,\n",
    "                            \"yaw\": 0.0,\n",
    "                            \"timestamp\": 34514.21\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": 6.0,\n",
    "                            \"y\": 8.1,\n",
    "                            \"yaw\": 0.0,\n",
    "                            \"timestamp\": 34514.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": 10.0,\n",
    "                            \"y\": 8.1,\n",
    "                            \"yaw\": 0.0,\n",
    "                            \"timestamp\": 34515.21\n",
    "                        },\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"probability\" : 0.219,\n",
    "                    \"trajectory\"  : [\n",
    "                        {\n",
    "                            \"x\": -10.0,\n",
    "                            \"y\": 8.1,\n",
    "                            \"yaw\": 0.0,\n",
    "                            \"timestamp\": 34512.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -7.0,\n",
    "                            \"y\": 7.5,\n",
    "                            \"yaw\": -5.2,\n",
    "                            \"timestamp\": 34513.21\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -4.0,\n",
    "                            \"y\": 6.1,\n",
    "                            \"yaw\": -32.0,\n",
    "                            \"timestamp\": 34513.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -3.0,\n",
    "                            \"y\": 4.1,\n",
    "                            \"yaw\": -73.2,\n",
    "                            \"timestamp\": 34514.21\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -2.0,\n",
    "                            \"y\": 1.2,\n",
    "                            \"yaw\": -90.0,\n",
    "                            \"timestamp\": 34514.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -2.0,\n",
    "                            \"y\":-2.8,\n",
    "                            \"yaw\": -90.0,\n",
    "                            \"timestamp\": 34515.21\n",
    "                        },\n",
    "                    ]\n",
    "\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"id\" : 1,\n",
    "            \"length\": 3.4,\n",
    "            \"width\" : 1.5,\n",
    "            \"predictions\" : [\n",
    "                {\n",
    "                    \"probability\" : 1.0,\n",
    "                    \"trajectory\" : [\n",
    "                        {\n",
    "                            \"x\": 10.0,\n",
    "                            \"y\": 12.1,\n",
    "                            \"yaw\": -180.0,\n",
    "                            \"timestamp\": 34512.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": 6.0,\n",
    "                            \"y\": 12.1,\n",
    "                            \"yaw\": -180.0,\n",
    "                            \"timestamp\": 34513.21\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": 2.0,\n",
    "                            \"y\": 12.1,\n",
    "                            \"yaw\": -180.0,\n",
    "                            \"timestamp\": 34513.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -2.0,\n",
    "                            \"y\": 12.1,\n",
    "                            \"yaw\": -180.0,\n",
    "                            \"timestamp\": 34514.21\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -6.0,\n",
    "                            \"y\": 12.1,\n",
    "                            \"yaw\": -180.0,\n",
    "                            \"timestamp\": 34514.71\n",
    "                        },\n",
    "                        {\n",
    "                            \"x\": -10.0,\n",
    "                            \"y\": 12.1,\n",
    "                            \"yaw\": -180.0,\n",
    "                            \"timestamp\": 34515.21\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the predicted trajectories shown above only extend out a few seconds\n",
    "  - in reality the predictions we make extend to a horizon of $10-20$ seconds\n",
    "- the trajectories shown have $0.5$ second resolution\n",
    "  - in reality we would generate slightly finer-grained predictions\n",
    "- this example only shows vehicles but in reality we would also generate predictions for all dynamic objects in view\n",
    "\n",
    "\n",
    "- **Q:** How many possible trajectories are given for the car on the left (with id of 0) (image above)?\n",
    "- **A:** 2 and the probabilities for those two trajectories sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Based vs Data-Driven Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- imagine a T-shaped intersection\n",
    "- the blue self-driving car pulls up to that stop sign and would like to make a left turn but it sees this green car coming from the left\n",
    "- if the green car is turning right, it is safe for the blue car to go, but if the green car is going straight, then the blue car should wait\n",
    "\n",
    "<img src=\"resources/model_based_vs_data_driven.png\"/>\n",
    "\n",
    "- the way we would handle this with the model based approach is as follows:\n",
    "  - we would come up with two process models, one for going straight and one for turning right\n",
    "  - we would use some simple trajectory generator to figure out what trajectory we would expect to see if the driver were going straight or turning right\n",
    "  - we would pay attention to the actual behavior of the target vehicle and using a multimodal estimation algorithm (which is still a black box for now) we would compare observed trajectory to the ones we would expect for each of our models\n",
    "  - based on that we would assign a probability to each of the possible trajectories\n",
    "- the important takeaway for purely model based prediction is that we have some bank of possible behaviors and each has a mathematical model of motion which takes into account the physical capabilities of the object as well as the constraints imposed by the road traffic laws and other restrictions\n",
    "\n",
    "\n",
    "- with the purely data driven approach we have a truly blackbox algorithm and this algorithm will be trained on lots of training data\n",
    "- once it's trained we just fitted the observed behavior and let it make a prediction about what will happen next\n",
    "\n",
    "\n",
    "- we can see that each approach has its own strengths\n",
    "- model based approaches incorporate our knowledge of physics constraints imposed by the road traffic etc.\n",
    "- data driven approaches are nice because they let us use data to extract subtle patterns that would otherwise be missed by model based approaches\n",
    "  - for example differences in vehicle behavior at an intersection during different times of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which is Best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neither approach (model based or data driven) is strictly better than the other but there are certain situations in which one is more useful than the other\n",
    "- think about the following situations and whether model-based or data-driven approaches would be more useful\n",
    "\n",
    "\n",
    "- **Q:** Determining maximum safe turning speed on a wet road.\n",
    "- **A:** In this situation we could use a model based approach to incorporate our knowledge of physics (friction, forces, etc...) to figure out exactly (or almost exactly) when a vehicle would begin to skid on a wet road.\n",
    "\n",
    "\n",
    "- **Q:** Predicting the behavior of an unidentified object sitting on the road.\n",
    "- **A:** Even with data driven approaches this would still be a very hard problem but since we don't even know what this object is, a model based approach to prediction would be nearly impossible.\n",
    "\n",
    "\n",
    "- **Q:** Predicting the behavior of a vehicle on a two lane highway in light traffic.\n",
    "- **A:** You could really use either approach (or a hybrid approach) in this situation. On the one hand there are very few behaviors we need to model in a highway driving situation and the physics are all very well understood so model based approaches could work. On the other hand it would be relatively easy to collect a lot of training data in similar situations so a purely data driven approach could work too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Driven Example - Trajectory Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- since you already went through a machine learning class, we won't go into these techniques in too much detail\n",
    "- in this video, I would like to show you one example that is representative of what these algorithms are good at--trajectory clustering\n",
    "- as is the case with all data driven prediction techniques, there will be two phases\n",
    "  - an offline training phase where the algorithm learns a model from data\n",
    "  - an online prediction phase where it uses that model to generate predictions\n",
    "\n",
    "\n",
    "- [Trajectory Clustering for Motion Prediction](http://video.udacity-data.com.s3.amazonaws.com/topher/2017/July/5978c2c6_trajectory-clustering/trajectory-clustering.pdf) - *Sung, Feldman, and Rus*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's discuss the offline phase first\n",
    "  - the first step is to get a lot of data which you might do by placing a static camera at an intersection\n",
    "  - then, we have to clean the data since some of the cars we observe may be occluded or something else went wrong in the processing step--so we need to discard the bad data\n",
    "  - once the data is gathered and cleaned up, we would be left with a bunch of trajectories that look something like this (white lines)\n",
    "  - next, we need to define some mathematical measure of trajectory similarity\n",
    "    - there are many ways to do this but intuitively we want something that says a trajectory like this one in red is more similar to this one in pink than it is to this one in blue, even though the red and blue trajectories overlap more closely for a while than the red and pink ever do\n",
    "  - once we have a measure of similarity we can use a machine learning algorithm like agglomerative clustering or a spectral clustering to cluster these trajectories (perform unsupervised learning)\n",
    "    - in the case of a four-way stop intersection, we would expect to see 12 clusters since at each of the four stop signs cars can do one of three things: turn right, go straight or turn left\n",
    "    - if we were looking at just one of those four stop signs, we would expect to see a cluster of trajectories for left turns, going straight, and turning right\n",
    "    - note that in some situations you may obtain even more clusters than that--for example, if this lane is controlled by a traffic light instead of stop, your clustering algorithm will probably create twice as many clusters\n",
    "  - once the trajectories have been grouped into clusters, it is useful to define what prototype trajectories look like for each cluster\n",
    "  - at this point, we have a trained model of typical car behavior at this intersection and the next step is to use this model on the road to actually generate predictions\n",
    "\n",
    "<img src=\"resources/offline_phase_lines.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- once our clustering algorithm has identified clusters and prototype trajectories, in this case three clusters with three prototype trajectories each, we can begin the job of online prediction for a vehicle that we meet on the road\n",
    "  - first, we observe the vehicle's partial trajectory\n",
    "  - next we compare it to the corresponding segments of the prototype trajectories for each cluster\n",
    "    - this comparison is done using the same similarity measure we used earlier to perform the clustering\n",
    "  - the belief for each cluster is updated based on how similar the partial trajectory is to the prototype trajectories\n",
    "  - finally, we compute a predicted trajectory for each cluster\n",
    "    - for example, by taking the most similar prototype trajectory\n",
    "\n",
    "<img src=\"resources/online_prediction_example.png\"/>\n",
    "\n",
    "- let's make this more clear by following this car forward in time from $t = 0$ to $t = 1$--let's go through these steps\n",
    "  - one, we observe the partial trajectory between time $0$ and $1$\n",
    "    - it is this green line behind the vehicle\n",
    "  - two, well since all of the prototype trajectories overlap up to this point, the trajectory comparison step will yield the same probability for each cluster\n",
    "  - three, even though there is no clear winner within each cluster we still have to choose one prototype trajectory to represent each cluster and we broadcast these three trajectories with their associated probabilities\n",
    "  - next, a $t = 2$ things get more interesting\n",
    "    - now when you make a comparison of the partial trajectory with the nine prototype trajectories, we find that the vehicle's partial trajectory seems more similar to the red than purple or blue\n",
    "    - when we update the associated probabilities we might get something like this (third column)--note that red grows in probability and the blue and purple both shrink, but blue shrinks more than purple since the partial trajectory is a worse match for blue\n",
    "  - then, we pick the best prototype trajectory for each cluster and use them to represent the future trajectory of the car\n",
    "  - as we continue this process, we see the probability for the red cluster quickly approaches one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking about Model Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data driven approaches can be very useful, particularly when we have access to plenty of training data but in some ways purely data driven approaches are naïve since they rely solely on historical evidence to make predictions about likely future behavior\n",
    "- ideally, we would also like to include, in our predictions, all the insights we have about driver behavior, physics, or vehicle dynamics\n",
    "- this is where model based approaches can help\n",
    "- the way these approaches typically work is as follows:\n",
    "  - for each object identify all the behaviors that object is likely to do in the current situation\n",
    "    - the behavior for a vehicle could be something like change lanes, turn left and for a pedestrian it could be cross the street on pedestrian crossing\n",
    "    - for our intersection scenario, the behaviors could be go straight, turn left, turn right\n",
    "    - whatever it is, it needs to be something that we can describe mathematically\n",
    "  - step two, define a process model for each behavior\n",
    "    - a process model is a mathematical description of object motion for behavior\n",
    "    - it is a function which can be used to compute the state of the object at time $t + 1$ from the state at time $t$\n",
    "    - the process model must incorporate some uncertainty which represents how much we trust our model\n",
    "    - if you keep running the process models your uncertainty will increase\n",
    "  - once we have a process model for each behavior we can go to the next step, step three, which is to use the process models to compute the probability of each behavior (i.e. update beliefs by comparing the observation with the output of the process model)\n",
    "    - this is done by taking the observed state of the object at time $t-1$, running the process models to compute the expected state of the object at time $t$\n",
    "    - then we compare the observed state of the object at time $t$ with what our process models predicted\n",
    "    - we use a multimodal estimation algorithm to derive the probability of each maneuver\n",
    "    - the purpose of these algorithms is to maintain some belief about how likely it is that the driver intends to perform each behavior--we'll go into more detail later\n",
    "  - the fourth and final step is to predict a trajectory for each behavior\n",
    "    - this is done easily by iterating on the process models until the prediction horizon is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frenet Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- before we discuss process models, we should mention \"Frenet Coordinates\", which are a way of representing position on a road in a more intuitive way than traditional $(x,y)$ Cartesian Coordinates\n",
    "- with Frenet coordinates, we use the variables $s$ and $d$ to describe a vehicle's position on the road\n",
    "  - the $s$ coordinate represents distance along the road (also known as longitudinal displacement) \n",
    "  - the $d$ coordinate represents side-to-side position on the road (also known as lateral displacement)\n",
    "\n",
    "\n",
    "- why do we use Frenet coordinates?\n",
    "- imagine a curvy road like the one below with a Cartesian coordinate system laid on top of it\n",
    "\n",
    "<img src=\"resources/frenet_1.png\"/>\n",
    "\n",
    "- using these Cartesian coordinates, we can try to describe the path a vehicle would normally follow on the road\n",
    "\n",
    "<img src=\"resources/frenet_2.png\"/>\n",
    "\n",
    "<img src=\"resources/frenet_3.png\"/>\n",
    "\n",
    "- notice how curvy that path is!--if we wanted equations to describe this motion it wouldn't be easy!\n",
    "\n",
    "\n",
    "- ideally, it should be mathematically easy to describe such common driving behavior--but how do we do that?\n",
    "- one way is to use a new coordinate system\n",
    "- now instead of laying down a normal Cartesian grid, we do something like you see below\n",
    "\n",
    "<img src=\"resources/frenet_4.png\"/>\n",
    "\n",
    "- here, we've defined a new system of coordinates\n",
    "- at the bottom we have $s=0$ to represent the beginning of the segment of road we are thinking about and $d=0$ to represent the center line of that road\n",
    "- to the left of the center line we have negative $d$ and to the right $d$ is positive\n",
    "\n",
    "\n",
    "- so what does a typical trajectory look like when presented in Frenet coordinates?\n",
    "\n",
    "<img src=\"resources/frenet_5.png\"/>\n",
    "\n",
    "<img src=\"resources/frenet_6.png\"/>\n",
    "\n",
    "- it looks straight!\n",
    "- in fact, if this vehicle were moving at a constant speed of $v_0$ we could write a mathematical description of the vehicle's position as:\n",
    "  - $s(t) = v_0t$\n",
    "  - $d(t) = 0$\n",
    "\n",
    "\n",
    "- we'll be working with Frenet coordinates a good deal in the rest of the course, because straight lines are so much easier than curved ones\n",
    "\n",
    "<img src=\"resources/frenet_7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's consider some process models for a situation where a self-driving car is trying to merge onto a highway\n",
    "- but, let's say there is another vehicle in the rightmost lane\n",
    "- now, this vehicle might do a few things: it might just ignore us, it might speed up to let us merge behind it, it might slow down to let us get ahead of it, or it might change lanes\n",
    "- for each of these behaviors, we want to come up with a process model that formalizes the likely motion of the car\n",
    "  - if the car ignores us, it will likely follow lane A (current) with constant velocity\n",
    "  - if they speed up, we may choose to model their motion as lane following with positive acceleration\n",
    "  - if they slow down, we would do the same thing, but with negative acceleration\n",
    "  - lane changing, we could model as lane following on lane B (left of lane A), with constant velocity\n",
    "\n",
    "\n",
    "- what is lane following--how do we describe it mathematically?\n",
    "- in general, there is a tradeoff between simplicity and accuracy when choosing a process model\n",
    "  - one very simple approach is to treat the car as a point particle with holonomic properties\n",
    "    - this means we assume the point can move in any direction at any time, which of course is a very simplistic assumption\n",
    "    - the simplest motion models are linear--constant velocity lane following for any coordinates where the car moves forward at each timestep, and is assumed to keep a constant distance to the lane center\n",
    "    - in practice, linear point models usually wind up being too simplistic\n",
    "  - the next step in complexity happens when we allow non-linearities into our model\n",
    "    - typically, if you start incorporating heading into our state vector, you will end up with sines and cosines in our model equations\n",
    "    - note the presence of cosine and sine, which are where the non-linearity comes in\n",
    "  - the next jump in complexity happens when we take into account that a car is a non-holonomic system\n",
    "    - a popular approach is to use a bicycle model, which takes two inputs, the steering angle and the acceleration\n",
    "    - for the steering angle, we could use a PID controller with the target lane center line as the reference line\n",
    "    - for the acceleration, we could once again use a constant velocity model, or a constant acceleration model, or if we wanted more complex acceleration behavior, we could use a PID controller with the speed limit as the target\n",
    "\n",
    "\n",
    "- in practice, these sorts of models tend to strike a good balance between simplicity and accuracy but you could always go more complex by including more details about vehicle dynamics\n",
    "  - for example, you could use a dynamic bicycle model\n",
    "    - note the presence of terms like $F_{c,f}$, which represents the lateral force on the tires at the front of the vehicle, and $F_{c,r}$, which represents the lateral force on the rear tire\n",
    "    - you could even add more complexity and model the four wheels of the car\n",
    "- while these models are technically more accurate than any of the others, in practice, using them doesn't usually make sense for prediction\n",
    "- there is so much uncertainty inherent to predicting the behaviors of other drivers that minor accuracy improvements to process models just aren't worth the computational overhead that they come with\n",
    "\n",
    "<img src=\"resources/process_models.png\"/>\n",
    "\n",
    "- note how all the models contain an additional term $W$\n",
    "- this is where the uncertainty on the process model is stored\n",
    "- a classic choice to represent uncertainty is a multivariate Gaussian with zero mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on Process Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- later in the lesson I'm going to ask you to read a paper titled [A comparative study of multiple-model algorithms for maneuvering target tracking](https://d17h27t6h515a5.cloudfront.net/topher/2017/June/5953fc34_a-comparative-study-of-multiple-model-algorithms-for-maneuvering-target-tracking/a-comparative-study-of-multiple-model-algorithms-for-maneuvering-target-tracking.pdf) but for now I'd like you to take a look at section 3.1 and 3.2 only\n",
    "  - this section, titled MM Tracking Algorithms' Design, discusses the 9 process models used in the earlier part of the paper\n",
    "\n",
    "\n",
    "### Notes on Notation\n",
    "\n",
    "#### 1. Matrix Notation\n",
    "\n",
    "- when you see something like the following: $F_{CV} = \\text{diag}[F_2, F_2], F_2 = \\begin{bmatrix} 1 & T \\\\ 0 & 1 \\end{bmatrix}$ it means that $F$ is a 4x4 matrix, with $F_{2}$ as blocks along the diagonal\n",
    "- written out fully, this means: $F_{CV} = \\begin{bmatrix} 1 & T & 0 & 0\\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & T \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}$\n",
    "\n",
    "#### 2. State Space\n",
    "\n",
    "- the process models all use cartesian coordinates\n",
    "- the state space is $\\mathbf{x} = \\begin{bmatrix} x\\\\ \\dot{x} \\\\ y \\\\ \\dot{y} \\end{bmatrix}$\n",
    "\n",
    "#### 3. Variables\n",
    "\n",
    "- the equation $x_{k} = Fx_{k-1} + Gu_{k-1} + Gw_k, \\ \\ w_k \\sim \\mathcal{N}(0,Q)$ should be read as follows:\n",
    "  - the predicted state at time $k(x_k)$ is given by evolving $(F)$ the previous state $(x_{k-1})$, incorporating $(G)$ the controls $(u_{k-1})$ given at the previous time step, and adding normally distributed noise $(w_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we have talked about individual process models but we haven't yet talked about how to maintain some beliefs about which behavior the driver intends to perform\n",
    "- this is the role of multimodal estimation algorithms\n",
    "- a simple approach to multimodal estimation is called *autonomous multiple model estimation* or *AMM*\n",
    "- while describing AMM, I will use the same notation that is used in a paper\n",
    "  - the variable $M$ represents the number of process models or behaviors and each variable $\\mu$ represents the probability of behavior\n",
    "\n",
    "\n",
    "- to understand how these probabilities are computed, let's go back to our T intersection example\n",
    "- let's say we have two process models here--one to go straight and one to turn right and they both have Gaussian uncertainty\n",
    "- let's say that we observe this state for the vehicle at time $k-1$ and we observe this state for the vehicle at time $k$\n",
    "- in order to compute the new probabilities for the behaviors based on the new observation, we will run our two process models for one step starting from the state at time $k-1$ \n",
    "- when we do this, we get these two expected states (white clouds) for time $k$\n",
    "\n",
    "<img src=\"resources/multimodal_estimation_1.png\"/>\n",
    "\n",
    "- if we just look at what the distribution on the vehicle's $s$ coordinate looks like for the two expected states, this is what we see\n",
    "  - the red curve gives the probability density function of $s$ for turning right,\n",
    "  - the blue curve represents going straight\n",
    "  - the observation at timestep $k$ is somewhere here (green)\n",
    "- we can see that this observation is substantially more consistent with turn right than it is with go straight\n",
    "- this is measured by the likelihood of the observation as for each model and the probability of each behavior is a function of these likelihoods and of the probabilities computed in the previous timestep\n",
    "\n",
    "<img src=\"resources/multimodal_estimation_2.png\"/>\n",
    "\n",
    "- the important quantity for the AMM is the ratio of these likelihoods after they get multiplied by the previous probability\n",
    "- the equation ends up looking like this ($\\mu_k^{(i)}$), where this term is the probability of model $i$ at timestep $k$\n",
    "  - it includes the probability of model $i$ at timestep $k-1$\n",
    "  - the $L$ term is the likelihood of the observation at time $k$ for that model\n",
    "  - the denominator just serves to normalize our probabilities so that they all sum to one\n",
    "  - $M$, in this situation would be two since we are only considering two maneuvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Data Driven and Model Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data-Driven Approaches\n",
    "\n",
    "- they solve the prediction problem in two phases:\n",
    "  - offline training\n",
    "    - in this phase the goal is to feed some machine learning algorithm a lot of data to train it\n",
    "    - for the trajectory clustering example this involved:\n",
    "      - define similarity - we first need a definition of similarity that agrees with human common-sense definition\n",
    "      - unsupervised clustering - at this step some machine learning algorithm clusters the trajectories we've observed\n",
    "      - define prototype trajectories - for each cluster identify some small number of typical \"prototype\" trajectories\n",
    "  - online prediction\n",
    "    - once the algorithm is trained we bring it onto the road\n",
    "    - when we encounter a situation for which the trained algorithm is appropriate (returning to an intersection for example) we can use that algorithm to actually predict the trajectory of the vehicle\n",
    "    - for the intersection example this meant:\n",
    "      - observe partial trajectory\n",
    "        - as the target vehicle drives we can think of it leaving a \"partial trajectory\" behind it\n",
    "      - compare to prototype trajectories\n",
    "        - we can compare this partial trajectory to the corresponding parts of the prototype trajectories\n",
    "        - when these partial trajectories are more similar (using the same notion of similarity defined earlier) their likelihoods should increase relative to the other trajectories\n",
    "      - generate predictions\n",
    "        - for each cluster we identify the most likely prototype trajectory\n",
    "        - we broadcast each of these trajectories along with the associated probability (see the image below)\n",
    "\n",
    "<img src=\"resources/online_prediction_summary.jpg\"/>\n",
    "\n",
    "\n",
    "#### Model Based Approaches\n",
    "\n",
    "- you can think of model based solutions to the prediction problem as also having an \"offline\" and \"online\" component\n",
    "- in that view, this approach requires:\n",
    "  - defining process models (offline)\n",
    "    - you saw how process models can vary in complexity from very simple... $\\begin{bmatrix} \\dot{s}\\\\ \\dot{d} \\end{bmatrix} = \\begin{bmatrix} s_{0} \\\\ 0 \\end{bmatrix} + \\mathbf{w}$ to very complex... $\\begin{bmatrix} \\ddot{s} \\\\ \\ddot{d} \\\\ \\ddot{\\theta} \\end{bmatrix} = \\begin{bmatrix} \\dot{\\theta}\\dot{d} + a_s \\\\ -\\dot{\\theta}\\dot{s} + \\frac{2}{m}(F_{c,f}\\cos\\delta + F_{c,r}) \\\\ \\frac{2}{I_z} (l_f F_{c,f} - l_rF_{c,r}) \\end{bmatrix} + \\mathbf{w}$\n",
    "  - using process models to compare driver behavior to what would be expected for each model\n",
    "    - process models are first used to compare a target vehicle's observed behavior to the behavior we would expect for each of the maneuvers we've created models for\n",
    "    - the pictures below help explain how process models are used to calculate these likelihoods\n",
    "     <img src=\"resources/process_models_likelihoods.jpg\"/>\n",
    "    - on the left we see two images of a car\n",
    "      - at time $k-1$ we predicted where the car would be if it were to go straight vs go right\n",
    "      - then at time $k$ we look at where the car actually is\n",
    "      - the graph on the right shows the car's observed $s$ coordinate along with the probability distributions for where we expected the car to be at that time\n",
    "      - in this case, the $s$ that we observe is substantially more consistent with turning right than going straight\n",
    "  - probabilistically classifying driver intent by comparing the likelihoods of various behaviors with a multiple-model algorithm\n",
    "    - in the image above you can see a bar chart representing probabilities of various clusters over time\n",
    "    - multiple model algorithms serve a similar purpose for model based approaches: they are responsible for maintaining beliefs for the probability of each maneuver\n",
    "    - the algorithm we discussed is called the Autonomous Multiple Model algorithm (AMM) and it can be summarized with this equation: $\\large \\mu_k^{(i)} = \\frac{\\mu_{k-1}^{(i)}L_k^{(i)}}{\\sum_{j=1}^M\\mu_{k-1}^{(j)}L_k^{(j)}}$\n",
    "    - or, if we ignore the denominator (since it just serves to normalize the probabilities), we can capture the essence of this algorithm with $\\mu_k^{(i)} \\propto \\mu_{k-1}^{(i)}L_k^{(i)}$ where the $\\mu_k^{(i)}$ is the probability that model number $i$ is the correct model at time $k$ and $L_k^{(i)}$ is the likelihood for that model (as computed by comparison to process model)\n",
    "  - extrapolating process models to generate trajectories\n",
    "    - trajectory generation is straightforward once we have a process model\n",
    "    - we simply iterate our model over and over until we've generated a prediction that spans whatever time horizon we are supposed to cover\n",
    "    - note that each iteration of the process model will necessarily add uncertainty to our prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Hybrid Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- so far you have seen that prediction can be done with model based or data driven approaches\n",
    "- you learned that model based approaches incorporate our knowledge of the objects motion dynamics with process models, handle uncertainty on maneuvers using multimodal estimators, and you have seen that there are many ways to implement model based approaches\n",
    "- in learning about data driven approaches you saw that there are many versions of \"data driven\" approaches and that these approaches can extract subtle patterns from training data which means they can produce predictions which are very well tailored to a specific driving situation\n",
    "\n",
    "\n",
    "- in practice, the best way to do prediction is often by taking a hybrid approach that takes advantage of the strengths of both types of approaches\n",
    "- remember earlier when we talked about how model based approaches combine process models with a multimodal estimator?\n",
    "- well, the multimodal estimator could be replaced with a machine learning approach\n",
    "- to replace that component with a machine learning approach, the type of algorithm we need is a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one strategy that is often used in hybrid approaches for behavior classification is to combine a classifier with a filter\n",
    "- for now we will introduce a simple behavior classifier, Naive Bayes\n",
    "\n",
    "<img src=\"resources/naive_bayes.png\"/>\n",
    "\n",
    "- let's walk through how Naive Bayes works by using an example\n",
    "- we are going to reason on gender using statistics of two feature variables: height and weight\n",
    "- as an output we want the probability that a person is male or female given their height or weight\n",
    "- in a Naive Bayes classifier, the probability of being male given height and weight is just the probability of the height given male times the probability of that weight given male multiplied by the prior probability of being male divided by the probability of the height and weight in the overall population\n",
    "- the reason why this algorithm is called Naive Bayes is that it assumes that all features contribute independently while in reality there is correlation between height and weight in people\n",
    "- in practice the independence assumption often winds up working\n",
    "- the equation above can be simplified--this term (red) will affect both probabilities male and female in the same way--it is just a normalization factor\n",
    "  - this means we can first compute this part of the equation both for male and female and then compute the final probability of male given height and weight and probability of female given height and weight by normalizing them to make them sum to one\n",
    "\n",
    "\n",
    "- the problem is all about finding these terms\n",
    "- often, we can assume it goes in distribution for the feature variables\n",
    "- if you make this assumption the algorithm is then called Gaussian Naive Bayes\n",
    "- so in practice, implementing a good Gaussian Naive Bayes classifier is all about:\n",
    "  - selecting the correct feature variables for the classification problem\n",
    "    - this is where we can use some human intuition combined with feature selection algorithms to anticipate what factors are relevant for a given classification situation\n",
    "    - eye color for example would not be very useful in predicting gender\n",
    "  - identifying some good means and variances for different classes\n",
    "     - we can either guess these numbers or we can look at lots of data to learn them\n",
    "     - for example, if you have access to lots of data about how drivers handle intersections and if you define some good features which indicating tension's of drivers you could use Naive Bayes to compute the probability of each behavior at each time step\n",
    "    - for the trajectory prediction part you could use one of the following models we talked about earlier\n",
    "\n",
    "\n",
    "- **Q:** A car on a highway is approaching an exit ramp. We want to classify the driver's intent as \"go straight\" or \"exit right\". Which of the following state variables would be least useful to this classification?\n",
    "- **A:** The $s$ coordinate will not help in distinguishing between these two behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in this exercise you will implement a Gaussian Naive Bayes classifier to predict the behavior of vehicles on a highway\n",
    "- in the image below you can see the behaviors you'll be looking for on a 3 lane highway (with lanes of 4 meter width)\n",
    "- the dots represent the $d$ (y axis) and $s$ (x axis) coordinates of vehicles as they either:\n",
    "  - change lanes left (shown in blue)\n",
    "  - keep lane (shown in black)\n",
    "  - change lanes right (shown in red)\n",
    "\n",
    "<img src=\"resources/naive_bayes_highway.png\"/>\n",
    "\n",
    "- your job is to write a classifier that can predict which of these three maneuvers a vehicle is engaged in given a single coordinate (sampled from the trajectories shown below)\n",
    "- each coordinate contains 4 features:\n",
    "  - $s$, $d$, $\\dot{s}$, $\\dot{d}$\n",
    "- you also know the lane width is 4 meters (this might be helpful in engineering additional features for your algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- implement the `train(data, labels)` method in the class `GNB` in `classifier.cpp`\n",
    "  - training a Gaussian Naive Bayes classifier consists of computing and storing the mean and standard deviation from the data for each label/feature pair\n",
    "    - for example, given the label \"change lanes left” and the feature $\\dot{s}$, it would be necessary to compute and store the mean and standard deviation of $\\dot{s}$ over all data points with the \"change lanes left” label\n",
    "  - additionally, it will be convenient in this step to compute and store the prior probability $p(C_k)$ for each label $C_k$\n",
    "    - this can be done by keeping track of the number of times each label appears in the training data\n",
    "- implement the `predict(observation)` method in `classifier.cpp`\n",
    "  - given a new data point, prediction requires two steps:\n",
    "    - compute the conditional probabilities for each feature/label combination\n",
    "      - for a feature $x$ and label $C$ with mean $\\mu$ and standard deviation $\\sigma$ (computed in training), the conditional probability can be computed using the formula [here](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes): $p(x = v | C) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp^{-\\frac{(v-\\mu)^2}{2\\sigma^2}}$\n",
    "        - here $v$ is the value of feature $x$ in the new data point\n",
    "    - use the conditional probabilities in a Naive Bayes classifier\n",
    "      - this can be done using the formula [here](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Constructing_a_classifier_from_the_probability_model): $y = \\underset{k\\in (1,\\ldots, K)}{argmax } \\,\\,p(C_k) \\prod^n_{i=1}p(x_i = v_i| C_k)$\n",
    "        - in this formula, the argmax is taken over all possible labels $C_k$ and the product is taken over all features $x_i$ with values $v_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- you are welcome to use some existing implementation of a Gaussian Naive Bayes classifier\n",
    "- but to get the best results you will still need to put some thought into what features you provide the algorithm when classifying\n",
    "- though you will only be given the 4 coordinates listed above, you may find that by \"engineering\" features you may get better performance\n",
    "  - for example: the raw value of the $d$ coordinate may not be that useful\n",
    "  - but `d % lane_width` might be helpful since it gives the relative position of a vehicle in it's lane regardless of which lane the vehicle is in\n",
    "\n",
    "\n",
    "- helpful resources\n",
    "  - [sklearn documentation on GaussianNB](http://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes)\n",
    "  - [Wikipedia article on Naive Bayes / GNB](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes)\n",
    "\n",
    "\n",
    "- `Nd013_Pred_Data` has all the training and testing data for this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- code is available in `code/01_implement_naive_bayes/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in this lesson, you learned about the prediction problem and the two main classes of solutions, model based solutions and data driven solutions\n",
    "- you also learned about one particular hybrid approach which uses a Gaussian naive bayes classifier to predict driver behavior\n",
    "- there isn't any one correct approach--that's part of what makes the prediction problem so fundamentally difficult\n",
    "\n",
    "\n",
    "- in fact, in this lesson we actually made a simplifying assumption by only considering one object at a time\n",
    "- if you were to take into account multiple objects, then you would also have to take into account interactions between those objects\n",
    "  - these interactions can get very complex, very quickly\n",
    "- fortunately, even when you only consider one object at a time, you can still make useful predictions\n",
    "  - this is especially true during highway driving which is the situation you'll be dealing with in the final project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
