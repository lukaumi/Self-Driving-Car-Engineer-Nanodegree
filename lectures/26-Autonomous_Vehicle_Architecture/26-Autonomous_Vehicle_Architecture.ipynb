{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- welcome to System Integration, the final module of the Udacity Self-Driving Car Nanodegree program\n",
    "- over the course of this program, you've built the major components of an autonomous vehicle system\n",
    "- in this module, we'll be discussing the system architecture used in the Udacity self-driving car so that you can fit all of the pieces together\n",
    "- Carla, the Udacity self-driving car, has four major subsystems\n",
    "  - the first is the sensor subsystem, which consists of the hardware components that gather data about the environment\n",
    "    - this subsystem includes lidar, radar, cameras, and even GPS sensors mounted on the car\n",
    "  - the second is the perception subsystem, which consists of software to process sensor data\n",
    "    - you've built components of this subsystem already\n",
    "    - components in the perception subsystem combine sensor data into meaningful information\n",
    "  - the third is the planning subsystem which uses the output from perception for behavior planning and for both short and long range path planning\n",
    "  - the final subsystem is the control subsystem, which ensures that the vehicle follows the path provided by the planning subsystem and sends control commands to the vehicle\n",
    "\n",
    "\n",
    "- as we'll see, information generally flows through the subsystems from first to fourth, starting with sensor input and ending with control commands for the vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sensor Subsystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sensors are the hardware components your car uses to observe the world\n",
    "- by now, you are probably familiar with some of the most common types of autonomous vehicle sensors, such as: cameras, lidar, ...\n",
    "- but there are many other types of sensors used in autonomous vehicles\n",
    "- in the following exercise, test your knowledge of other types of sensors you might encounter--if you haven’t seen them before, here is more information about [IMU](https://en.wikipedia.org/wiki/Inertial_measurement_unit) and [Ultrasonic sensors](https://en.wikipedia.org/wiki/Parking_sensor)\n",
    "\n",
    "\n",
    "- **Q:** Which of the following would most likely belong to the sensor subsystem?\n",
    "- **A:** GPS, IMU (Inertial measurement unit), Ultrasonic sensors, Radar. Data from cameras is used to perform lane detection, but lane detection itself is part of the perception subsystem, not the sensor subsystem. Sensor fusion is the process of combining sensor data, so it is part of the perception subsystem, but it isn’t a physical sensor in the sensor subsystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perception Subsystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the perception subsystem processes data from sensors into structured information that can eventually be used for path planning or control\n",
    "- this is where most of the vehicles analysis of the environment takes place\n",
    "- we can think of the perception subsystem as the vehicle center of understanding about its environment\n",
    "- broadly speaking, we can further divide the perception subsystem itself into two underlying subsystems:\n",
    "  - detection\n",
    "    - it is responsible for understanding the surrounding environment\n",
    "    - it includes software components such as lane detection, traffic sign and traffic light detection and classification, object detection and tracking and free space detection\n",
    "  - localization\n",
    "    - it is responsible for using sensor and map data to determine the vehicle's precise location\n",
    "- each component of the perception subsystem relies on a different group of sensors\n",
    "\n",
    "\n",
    "- **Q:** The object detection component of the perception subsystem might process data from which of the following sensors?\n",
    "- **A:** The object detection component would most likely use sensor input from the camera, lidar, or radar. IMU can be used to measure a vehicle's linear and angular acceleration, but it is unlikely to be useful for detecting obstacles. GPS is useful for for determining a vehicle's approximate location, but it is unlikely to be useful for detecting obstacles.\n",
    "\n",
    "\n",
    "- **Q:** The localization component primarily uses data from which of the following sensors?\n",
    "- **A:** Localization for fully autonomous vehicles is commonly performed using lidar and a map, although all of these sensors could be used for localization (see [here](http://www.mdpi.com/1424-8220/16/3/280/htm) and [here](https://onlinelibrary.wiley.com/doi/full/10.1002/rob.21605) for interesting examples).\n",
    "\n",
    "\n",
    "- different components in the detection and localization subsystems draw information from different sensors\n",
    "- additionally, the localization subsystem requires map data which it uses to identify the vehicle's location\n",
    "\n",
    "\n",
    "- the perception subsystem passes the data from localization and detection to the planning subsystem\n",
    "- the planning subsystem determines what maneuver the vehicle should undertake next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Planning Subsystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- once data from the sensors has been processed by the perception subsystem, the vehicle can use that information to plan its path\n",
    "- there are several components of the planning system which you might remember from the path planning module:\n",
    "  - route planning\n",
    "    - it is responsible for high-level decisions about the path of the vehicle between two points on a map\n",
    "    - for example which roads, highways, or freeways to take\n",
    "    - this component is similar to the route planning feature found on many smartphones or modern car navigation systems\n",
    "  - prediction\n",
    "    - it estimates what actions (maneuvers) other objects on the road might take in the future\n",
    "    - for example, if another vehicle were identified, the prediction component would estimate its future trajectory\n",
    "  - behavior planning\n",
    "    - it determines what behavior the vehicle should exhibit at any point in time, i.e. what maneuver our vehicle should take\n",
    "    - for example stopping at a traffic light or intersection, changing lanes, accelerating, or making a left turn onto a new street are all maneuvers that may be issued by this component\n",
    "  - trajectory generation\n",
    "    - it plots the precise path we'd like our vehicle to follow\n",
    "    - based on the desired immediate behavior, the trajectory planning component will determine which trajectory is best for executing this behavior\n",
    "\n",
    "\n",
    "- **Q:** Which of the following perception components would provide useful information for the prediction component?\n",
    "- **A:** Although localization is unlikely to be used, many of the detection and classification components are needed for a vehicle to make informed predictions, including lane detection, free space detection, vehicle detection, and traffic sign classification.\n",
    "\n",
    "\n",
    "- **Q:** Which of the following perception components would provide useful information for behavioral planning?\n",
    "- **A:** All of the components above are used for the vehicle to determine the most appropriate behavior at a given time. Lane detection, Free space detection, Vehicle detection, Traffic sign classification, Localization. Additionally, the behavioral planning component will take inputs from the prediction component into account when determining the best behavior.\n",
    "\n",
    "\n",
    "- the planning subsystem takes in data from all of the components of the perception subsystem\n",
    "- additionally, map data is used for long range planning\n",
    "- once the vehicle has a planned trajectory, the next step is to execute that trajectory\n",
    "  - this is the responsibility of the control subsystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Control Subsystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the last subsystem in the vehicle is the control subsystem\n",
    "- this subsystem contains software components to ensure that the vehicle follows the path specified by the planning subsystem\n",
    "- the control subsystem may include components such as PID controllers, model predictive controllers, or other controllers\n",
    "- the control subsystem sense acceleration, braking, and steering commands to the vehicle\n",
    "- this completes the chain of information from sensors to actuation, and allows the vehicle to drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete system diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/autonomous_vehicle_architecture.png\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
