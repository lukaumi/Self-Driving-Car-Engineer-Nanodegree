{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "\n",
    "- the calibration images in the lesson exercise were taken with a different camera setting and a different chessboard pattern than the calibration images for the project\n",
    "- you need to set your chessboard size to $9x6$ for the project instead of $8x6$ as in the lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your curvature values make sense?\n",
    "\n",
    "- we're not expecting anything like perfection for this project, but a good check on whether or not your perspective transform worked as expected, your conversion from pixel space to world space was correct, and that you successfully calculated the radius of curvature is whether or not your results are roughly consistent with reality\n",
    "\n",
    "\n",
    "- here is an image from Google maps of where the project video was made (just northwest of the Udacity office!)\n",
    "  - I've drawn a circle to coincide with the first left curve in the project video\n",
    "  - this is a very rough estimate, but as you can see, the radius of that circle is approximately 1 km\n",
    "- you don't need to tune your algorithm to report exactly a radius of 1 km in the project, but if you're reporting 10 km or 0.1 km, you know there might be something wrong with your calculations!\n",
    "\n",
    "<img src=\"resources/googlemaps_image_radius.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offset\n",
    "\n",
    "- you can assume the camera is mounted at the center of the car, such that the lane center is the midpoint at the bottom of the image between the two lines you've detected\n",
    "- the offset of the lane center from the center of the image (converted from pixels to meters) is your distance from the center of the lane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking\n",
    "\n",
    "- after you've tuned your pipeline on test images, you'll run on a video stream, just like in the first project\n",
    "- in this case, however, you're going to keep track of things like where your last several detections of the lane lines were and what the curvature was, so you can properly treat new detections\n",
    "  - to do this, it's useful to define a `Line()` class to keep track of all the interesting parameters you measure from frame to frame\n",
    "- here's an example:\n",
    "\n",
    "```python\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None  \n",
    "```\n",
    "\n",
    "- you can create an instance of the `Line()` class for the left and right lane lines to keep track of recent detections and to perform sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check\n",
    "\n",
    "- ok, so your algorithm found some lines\n",
    "- before moving on, you should check that the detection makes sense\n",
    "- to confirm that your detected lane lines are real, you might consider:\n",
    "  - checking that they have similar curvature\n",
    "  - checking that they are separated by approximately the right distance horizontally\n",
    "  - checking that they are roughly parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look-Ahead Filter\n",
    "\n",
    "- once you've found the lane lines in one frame of video, and you are reasonably confident they are actually the lines you are looking for, you don't need to search blindly in the next frame\n",
    "- you can simply search within a window around the previous detection\n",
    "  - for example, if you fit a polynomial, then for each $y$ position, you have an $x$ position that represents the lane center from the last frame\n",
    "  - search for the new line within +/- some margin around the old line center\n",
    "  - if you need a reminder on how this works, make sure to go back and check the Finding the Lines: Search from Prior quiz from last lesson\n",
    "  - then check that your new line detections makes sense (i.e. expected curvature, separation, and slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset\n",
    "\n",
    "- if your sanity checks reveal that the lane lines you've detected are problematic for some reason, you can simply assume it was a bad or difficult frame of video, retain the previous positions from the frame prior and step to the next frame to search again\n",
    "- if you lose the lines for several frames in a row, you should probably start searching from scratch using a histogram and sliding window, or another method, to re-establish your measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "- even when everything is working, your line detections will jump around from frame to frame a bit and it can be preferable to smooth over the last $n$ frames of video to obtain a cleaner result\n",
    "- each time you get a new high-confidence measurement, you can append it to the list of recent measurements and then take an average over n past measurements to obtain the lane position you want to draw onto the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing\n",
    "\n",
    "- once you have a good measurement of the line positions in warped space, it's time to project your measurement back down onto the road!\n",
    "- let's suppose, as in the previous example, you have a warped binary image called warped, and you have fit the lines with a polynomial and have arrays called ploty, left_fitx and right_fitx, which represent the $x$ and $y$ pixel values of the lines\n",
    "- you can then project those lines onto the original image as follows:\n",
    "\n",
    "```python\n",
    "# Create an image to draw the lines on\n",
    "warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "# Combine the result with the original image\n",
    "result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "plt.imshow(result)\n",
    "```\n",
    "\n",
    "<img src=\"resources/original_image_with_line_drawn.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
